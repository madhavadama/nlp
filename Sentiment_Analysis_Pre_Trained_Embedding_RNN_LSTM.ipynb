{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "attachment_7__Sentiment_Analysis_Pre_Trained_Embedding_RNN_LSTM_lyst4741.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhavadama/nlp/blob/master/Sentiment_Analysis_Pre_Trained_Embedding_RNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As_sWHXZb3WX",
        "colab_type": "text"
      },
      "source": [
        "# Import Movie Review Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw3cW10ab3Wc",
        "colab_type": "text"
      },
      "source": [
        "Set the seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCjRpE8wb3Wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqfFoeZPb3Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Up2qplb3Wj",
        "colab_type": "text"
      },
      "source": [
        "Import the dataset as pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21bWLRxSb3Wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xog0YFEmb3Wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "your_local_path=\"C:/Users/tejks/Desktop/ML/practice/\"\n",
        "url = 'https://raw.githubusercontent.com/MatthieuBizien/Bag-popcorn/master/labeledTrainData.tsv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu9uIi7zb3Wp",
        "colab_type": "text"
      },
      "source": [
        "Data can be downloaded from Kaggle at the following URL\n",
        "\n",
        "- https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBp5DmlYb3Wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(url,header=0, delimiter=\"\\t\", quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQBZwDaCfI93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7ad23ccf-adef-4e99-8003-58ecea5bba5b"
      },
      "source": [
        "df.describe"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of               id  sentiment                                             review\n",
              "0       \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1       \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2       \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3       \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4       \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
              "...          ...        ...                                                ...\n",
              "24995   \"3453_3\"          0  \"It seems like more consideration has gone int...\n",
              "24996   \"5064_1\"          0  \"I don't believe they made this film. Complete...\n",
              "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
              "24998  \"10194_3\"          0  \"This 30 minute documentary BuÃ±uel made in the...\n",
              "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h...\n",
              "\n",
              "[25000 rows x 3 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reFOOlTXb3Wu",
        "colab_type": "text"
      },
      "source": [
        "Split Data into Training and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMXFtvTBb3Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYwwkDfmb3Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['review'],\n",
        "    df['sentiment'],\n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xQU3Uk6b3Wz",
        "colab_type": "text"
      },
      "source": [
        "# Build the Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5BB3qdBb3W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7F5pYf5b3W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_words = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osd56crPb3W5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = Tokenizer(num_words=top_words) # num_words -> Vocablury size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a7VagpUb3W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.fit_on_texts(X_train.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFTC5LVGb3W_",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Training and Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzTRPmUcb3XA",
        "colab_type": "text"
      },
      "source": [
        "Get the word index for each of the word in the review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OcVn-Yub3XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = t.texts_to_sequences(X_train.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdaKqDHfb3XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = t.texts_to_sequences(X_test.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5WkGtBIb3XG",
        "colab_type": "text"
      },
      "source": [
        "How many words in each review?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b6F0So4b3XG",
        "colab_type": "text"
      },
      "source": [
        "# Pad Sequences - Important"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3Nhcc2tb3XH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l8fO2yFb3XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_review_length = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0Tmrr8Ib3XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zrFRje9b3XU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJV5VCu5b3Xa",
        "colab_type": "text"
      },
      "source": [
        "# Build Embedding Matrix from Pre-Trained Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3yIaffyb3Xc",
        "colab_type": "text"
      },
      "source": [
        "Load pre-trained Gensim Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdWegV9Kb3Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Js039sMb3Xi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9f46b689-b023-40f8-a29e-06a040ffd038"
      },
      "source": [
        "word2vec = gensim.models.Word2Vec.load('word2vec-movie-50')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13MBYx4Eb3Xk",
        "colab_type": "text"
      },
      "source": [
        "Embedding Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhuMZcqHb3Xl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "bcb5a8e9-83af-4387-fc4b-4cf05b269c10"
      },
      "source": [
        "embedding_vector_length = word2vec.wv.syn0.shape[1]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K5u4VCYb3Xn",
        "colab_type": "text"
      },
      "source": [
        "Build matrix for current data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOrvPVHLb3Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((top_words + 1, embedding_vector_length))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFAN-Znab3Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
        "    if i > top_words:\n",
        "        break\n",
        "    if word in word2vec.wv.vocab:\n",
        "        embedding_vector = word2vec.wv[word]\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f38AHBTVb3Xt",
        "colab_type": "text"
      },
      "source": [
        "# Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM6aZFbxb3Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiOIu-AJb3Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten, LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZCxJ8hJb3Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW5ATKeLb3X0",
        "colab_type": "text"
      },
      "source": [
        "Add Embedding layer\n",
        " - Embedding Layer Input = Batch_Size * Length of each review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imce8bwzb3X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Embedding(top_words + 1,\n",
        "                    embedding_vector_length,\n",
        "                    input_length=max_review_length,\n",
        "                   weights=[embedding_matrix],\n",
        "                   trainable=False)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvYBD8TQb3X5",
        "colab_type": "text"
      },
      "source": [
        "Embedding Layer Output - \n",
        "[Batch_Size , Review Length , Embedding_Size]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkvtj57ab3X6",
        "colab_type": "text"
      },
      "source": [
        "Add Layer with 100 LSTM Memory Units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jWwq4Sqb3X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.add(dropout=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75BYPEulb3X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "#outout is last hidden state\n",
        "#batch_size, 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbzOIgzJb3YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.add(dropout=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onebijp_b3YE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFdrT1mmb3YG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "192d0e99-d6d4-4bc2-b514-7768ca6a0848"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1UW_mDcb3YK",
        "colab_type": "text"
      },
      "source": [
        "# Execute the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dT9c1Napb3YL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "6de29fef-5988-4bcb-fd3f-1e8cf028c283"
      },
      "source": [
        "model.fit(X_train,y_train,\n",
        "          epochs=30,\n",
        "          batch_size=128,          \n",
        "          validation_data=(X_test, y_test),\n",
        "         verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "20000/20000 [==============================] - 109s 5ms/sample - loss: 0.6904 - acc: 0.5149 - val_loss: 0.6858 - val_acc: 0.5276\n",
            "Epoch 2/30\n",
            "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.6814 - acc: 0.5631 - val_loss: 0.6860 - val_acc: 0.5440\n",
            "Epoch 3/30\n",
            "20000/20000 [==============================] - 107s 5ms/sample - loss: 0.6760 - acc: 0.5781 - val_loss: 0.6629 - val_acc: 0.6096\n",
            "Epoch 4/30\n",
            "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.6703 - acc: 0.5966 - val_loss: 0.6824 - val_acc: 0.5654\n",
            "Epoch 5/30\n",
            "20000/20000 [==============================] - 109s 5ms/sample - loss: 0.6862 - acc: 0.5379 - val_loss: 0.6884 - val_acc: 0.5262\n",
            "Epoch 6/30\n",
            "20000/20000 [==============================] - 105s 5ms/sample - loss: 0.6855 - acc: 0.5333 - val_loss: 0.6922 - val_acc: 0.5184\n",
            "Epoch 7/30\n",
            "20000/20000 [==============================] - 108s 5ms/sample - loss: 0.6855 - acc: 0.5346 - val_loss: 0.6815 - val_acc: 0.5340\n",
            "Epoch 8/30\n",
            "20000/20000 [==============================] - 109s 5ms/sample - loss: 0.6788 - acc: 0.5529 - val_loss: 0.6918 - val_acc: 0.5204\n",
            "Epoch 9/30\n",
            "20000/20000 [==============================] - 105s 5ms/sample - loss: 0.6683 - acc: 0.5950 - val_loss: 0.6551 - val_acc: 0.6360\n",
            "Epoch 10/30\n",
            "17408/20000 [=========================>....] - ETA: 13s - loss: 0.6479 - acc: 0.6357"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ4bb7UFb3YN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}